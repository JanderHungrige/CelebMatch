{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T10:01:21.725650Z",
     "start_time": "2020-03-19T10:01:19.008396Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Mar 16 14:54:36 2020\n",
    "\n",
    "@author: base\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from numpy import expand_dims\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('VideoCapture not opened')\n",
    "    #exit(0)\n",
    "\n",
    "#face_cascade = cv2.CascadeClassifier(str(Path.cwd() / 'haarcascade_frontalface_alt.xml'))\n",
    "#face_cascade = cv2.CascadeClassifier(str(Path.cwd() / 'lbpcascade_frontalface.xml'))\n",
    "face_cascade = cv2.CascadeClassifier(str(Path.cwd() / 'lbpcascade_frontalface_improved.xml'))\n",
    "\n",
    "Gesichter= False  # either True for only croped celebrity faces or False for original celbrity image. DEciding which images to show. Cropped or total resized image\n",
    "brt = 90  # value could be + or - for brightness or darkness\n",
    "gray=False\n",
    "p=35# frame size around detected face\n",
    "width=height=224 # size of the cropped image. Same as required for network\n",
    "mitte=np.empty(shape=[0, 0])\n",
    "mittleres_Gesicht_X=()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-19T10:01:27.067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "resnet50_features = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3),\n",
    "                                pooling='avg')  # pooling: None, avg or max\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('saved_model/my_model.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "\n",
    "EMBEDDINGS_Celebs=pd.read_json(Path.cwd() / 'EMBEDDINGS_8k.json')\n",
    "\n",
    "ret, frame = cap.read() \n",
    "framemitte=np.shape(frame)[1]/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize):\n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n",
    "    return listOfDf\n",
    "      \n",
    "def faceembedding(YourFace,CelebDaten):\n",
    "    Dist=[]\n",
    "    for i in range(len(CelebDaten.File)):\n",
    "        Celebs=np.array(CelebDaten.Embedding[i]) \n",
    "        Dist.append(np.linalg.norm(YourFace-Celebs))    \n",
    "    return Dist\n",
    "\n",
    "def faceembeddingNP(YourFace,CelebDaten):\n",
    "    Dist=[]\n",
    "    for i in range(len(CelebDaten)):\n",
    "        Celebs=np.array(CelebDaten[i]) \n",
    "        Dist.append(np.linalg.norm(YourFace-Celebs))    \n",
    "    return Dist\n",
    "\n",
    "celeb_embeddings=splitDataFrameIntoSmaller(EMBEDDINGS_Celebs, int(np.ceil(len(EMBEDDINGS_Celebs)/4)))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "# CAPTURE FRAME BY FRAME    \n",
    "    ret, frame = cap.read() \n",
    "    if gray==True:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame=cv2.flip(frame,1)  \n",
    "    cv2.namedWindow('frame', cv2.WND_PROP_FULLSCREEN)\n",
    "    cv2.setWindowProperty('frame', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    cv2.imshow('frame', frame) \n",
    "    \n",
    "#DECTECT FACE IN VIDEO CONTINUOUSLY       \n",
    "    faces_detected = face_cascade.detectMultiScale(frame, scaleFactor=1.2, minNeighbors=5)#, Size(50,50))\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        rechteck=cv2.rectangle(frame, (x-p, y-p+2), (x+w+p, y+h+p+2), (0, 255, 0), 2)  \n",
    "        #rechteck=cv2.rectangle(frame, (x-p, y-p+2), (x+int(np.ceil(height))+p, y+int(np.ceil(height))+p+2), (0, 0, 100), 2)  \n",
    "        cv2.imshow('frame', rechteck)     \n",
    "\n",
    "# DETECT KEY INPUT  - ESC OR FIND MOST CENTERED FACE  \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27: #Esc key\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    if key ==32: \n",
    "        mittleres_Gesicht_X=()\n",
    "        mitte=()\n",
    "        if faces_detected != (): # only if the cascader detected a face, otherwise error\n",
    "            start1 = time()\n",
    "#FIND MOST MIDDLE FACE            \n",
    "            for (x,y,w,h) in faces_detected:\n",
    "                mitte=np.append(mitte,(x+w/2))               \n",
    "            mittleres_Gesicht_X = (np.abs(mitte - framemitte)).argmin()\n",
    "            end1 = time()\n",
    "            print('detect middel face ', end1-start1)\n",
    "# FRAME THE DETECTED FACE\n",
    "            start2=time()\n",
    "            print(faces_detected[mittleres_Gesicht_X])\n",
    "            (x, y, w, h) = faces_detected[mittleres_Gesicht_X]\n",
    "            img=frame[y-p+2:y+h+p-2, x-p+2:x+w+p-2] #use only the detected face; crop it +2 to remove frame # CHECK IF IMAGE EMPTY (OUT OF IMAGE = EMPTY)     \n",
    "\n",
    "            if len(img) != 0: # Check if face is out of the frame, then img=[], throwing error\n",
    "                end2=time()\n",
    "                print('detect face ',end2-start2)\n",
    "\n",
    "# CROP IMAGE \n",
    "                start3=time()\n",
    "                if img.shape > (width,height): #downsampling\n",
    "                    img_small=cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA) #resize the image to desired dimensions e.g., 256x256  \n",
    "                elif img.shape < (width,height): #upsampling\n",
    "                    img_small=cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC) #resize the image to desired dimensions e.g., 256x256                      \n",
    "                cv2.imshow('frame',img_small)\n",
    "                cv2.waitKey(1) #hit any key\n",
    "                end3=time()\n",
    "                print('face crop', end3-start3)\n",
    "#CREATE FACE EMBEDDINGS\n",
    "                start4=time()\n",
    "                pixels = img_small.astype('float32')\n",
    "                samples = expand_dims(pixels, axis=0)\n",
    "                samples = preprocess_input(samples, version=2)\n",
    "                EMBEDDINGS = tflite_model.predict(samples)\n",
    "                #print('.')\n",
    "                end4=time()\n",
    "                print('create face embeddings' , end4-start4)\n",
    "# READ CELEB EMBEDDINGS AND COMPARE  \n",
    "                start_EU=time()\n",
    "                EuDist=[]\n",
    "                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "                    ergebniss_1=executor.submit(faceembeddingNP,EMBEDDINGS,np.array(celeb_embeddings[0].Embedding))\n",
    "                    ergebniss_2=executor.submit(faceembeddingNP,EMBEDDINGS,np.array(celeb_embeddings[1].Embedding))\n",
    "                    ergebniss_3=executor.submit(faceembeddingNP,EMBEDDINGS,np.array(celeb_embeddings[2].Embedding))\n",
    "                    ergebniss_4=executor.submit(faceembeddingNP,EMBEDDINGS,np.array(celeb_embeddings[3].Embedding))                    \n",
    "\n",
    "                if ergebniss_1.done() & ergebniss_2.done() & ergebniss_3.done() & ergebniss_4.done():\n",
    "                    EuDist.extend(ergebniss_1.result())\n",
    "                    EuDist.extend(ergebniss_2.result())\n",
    "                    EuDist.extend(ergebniss_3.result())\n",
    "                    EuDist.extend(ergebniss_4.result())\n",
    "                end_EU=time()\n",
    "                print('Create_EuDist', end_EU-start_EU)\n",
    "\n",
    "                start_Min=time()     \n",
    "                folder_idx= EMBEDDINGS_Celebs.Name[np.argmin(EuDist)]\n",
    "                image_idx = EMBEDDINGS_Celebs.File[np.argmin(EuDist)] \n",
    "                end_Min=time()\n",
    "                print('find minimum for facematch', end_Min-start_Min)\n",
    "                \n",
    "# PLOT IMAGES       \n",
    "                start6=time()\n",
    "                path=Path.cwd()\n",
    "\n",
    "                if Gesichter == False:\n",
    "                    pfad=str(Path.cwd() / 'sizeceleb_224_224' / str(folder_idx) / str(image_idx))\n",
    "                elif Gesichter == True:\n",
    "                    pfad=str(Path.cwd() / 'Celebs_faces' / str(folder_idx) / str(image_idx))    \n",
    "                    \n",
    "                Beleb=cv2.imread(pfad)                  \n",
    "                if np.shape(Beleb) != (width,height): \n",
    "                    Beleb=cv2.resize(Beleb, (np.shape(img_small)[0] ,np.shape(img_small)[1]), interpolation=cv2.INTER_AREA)\n",
    "                numpy_horizontal = np.hstack((img_small, Beleb))\n",
    "                cv2.namedWindow('ItsYou',cv2.WND_PROP_FULLSCREEN)\n",
    "                cv2.setWindowProperty('ItsYou', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "                numpy_horizontal= cv2.putText(numpy_horizontal, EMBEDDINGS_Celebs.Name[np.argmin(EuDist)], (5, 17), cv2.FONT_HERSHEY_COMPLEX_SMALL , 0.9, (116, 161, 142), 1)\n",
    "                cv2.imshow('ItsYou', numpy_horizontal)   \n",
    "                end6=time()\n",
    "                print('print found image', end6-start6)\n",
    "                total=time()\n",
    "                print('totaltime ', total-start1)\n",
    "                print(' Distance value: ', np.argmin(EuDist), ' | ' , 'Name: ', EMBEDDINGS_Celebs.Name[np.argmin(EuDist)],' | ' ,' Filename: ', EMBEDDINGS_Celebs.File[np.argmin(EuDist)])\n",
    "                \n",
    "# CLEARING ALL VARIANLES AND CONTINUE WITH THE PROGRAM\n",
    "                cv2.waitKey(0) #hit any key\n",
    "                faces_detected=None\n",
    "                mittleres_Gesicht_X=None        \n",
    "                img=None\n",
    "                img_small=None\n",
    "                pixels=None\n",
    "                samples=None\n",
    "                EMBEDDINGS=None          \n",
    "                cv2.destroyWindow('ItsYou')\n",
    "                if key == 27: #Esc key\n",
    "                    break\n",
    "\n",
    "\n",
    "            else: \n",
    "                rame= cv2.putText(frame, 'FACE MUST BE IN FRAME', (50, 50), cv2.FONT_HERSHEY_SIMPLEX , 0.8, (129, 173, 181), 2)\n",
    "                cv2.imshow('frame', frame)\n",
    "                cv2.waitKey(900)\n",
    "                \n",
    "        else:\n",
    "            print('noface detected')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
