{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live face comparison\n",
    "\n",
    "+ Determine if Mipi or USB Video0\n",
    "+ Read from camera\n",
    "+ Find all faces in image\n",
    "+ Indentify most middle face\n",
    "+ Crop image \n",
    "+ Determin face embeddings\n",
    "+ compare Embeddings - get min value index\n",
    "+ Find best image and present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T12:23:07.762547Z",
     "start_time": "2020-01-31T12:22:32.799113Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/base/anaconda3/envs/celeb/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect middel face  0.0001499652862548828\n",
      "[211  56 170 170]\n",
      "detect face  0.0006730556488037109\n",
      "size good\n",
      "face crop 0.000194549560546875\n",
      "create face embeddings 0.6247012615203857\n",
      " Distance value:  2321  |  Name:  John Cusack  |   Filename:  000006.jpg\n",
      "find facematch 2.793994665145874\n",
      "totaltime  3.4457197189331055\n",
      "print create image 13.680292844772339\n",
      "detect middel face  6.937980651855469e-05\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-27a5167d5f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# DETECT FACE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mstart2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces_detected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmittleres_Gesicht_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaces_detected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmittleres_Gesicht_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#use only the detected face; crop it +2 to remove frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#import time\n",
    "import math \n",
    "#from imutils import face_utils\n",
    "#import dlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from numpy import expand_dims\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from time import time\n",
    "\n",
    "# DEFINE VARIABLES\n",
    "#landmark_predictor = dlib.shape_predictor('/home/base/Documents/Git/Projekte/Face-celeb-rec/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(str(Path.cwd() / 'haarcascade_frontalface_alt.xml'))\n",
    "brt = 90  # value could be + or - for brightness or darkness\n",
    "cap = cv2.VideoCapture(0)\n",
    "gray=False\n",
    "p=35# frame size around detected face\n",
    "width=height=224 # size of the cropped image. Same as required for network\n",
    "mitte=np.empty(shape=[0, 0])\n",
    "mittleres_Gesicht_X=()\n",
    "\n",
    "resnet50_features = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3),\n",
    "                                pooling='avg')  # pooling: None, avg or max\n",
    "\n",
    "ret, frame = cap.read() \n",
    "framemitte=np.shape(frame)[1]/2\n",
    "\n",
    "while(True):\n",
    "# CAPTURE FRAME BY FRAME\n",
    "    \n",
    "    ret, frame = cap.read() \n",
    "    if gray==True:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    cv2.imshow('frame', frame) \n",
    "\n",
    "    \n",
    "\n",
    "#DECTECT FACE IN VIDEO CONTINUOUSLY       \n",
    "    faces_detected = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5)\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        rechteck=cv2.rectangle(frame, (x-p, y-p+2), (x+w+p, y+h+p+2), (0, 255, 0), 2)  \n",
    "        rechteck=cv2.rectangle(frame, (x-p, y-p+2), (x+int(np.ceil(height))+p, y+int(np.ceil(height))+p+2), (0, 0, 255), 2)  \n",
    "\n",
    "        cv2.imshow('frame', rechteck)     \n",
    "\n",
    "# DETECT KEY INPUT  - ESC OR FIND MOST CENTERED FACE  \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27: #Esc key\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    if key & 0xFF == ord('s'): \n",
    "        if mittleres_Gesicht_X is not ():\n",
    "            mittleres_Gesicht_X=()\n",
    "        #faces_detected = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5)\n",
    "        if faces_detected != (): # only if the cascader detected a face, otherwise error\n",
    "            start1 = time()\n",
    "            for (x,y,w,h) in faces_detected:\n",
    "                mitte=np.append(mitte,(x+w/2))\n",
    "                \n",
    "            mittleres_Gesicht_X = (np.abs(mitte - framemitte)).argmin()\n",
    "            end1 = time()\n",
    "            print('detect middel face ', end1-start1)\n",
    "# DETECT FACE\n",
    "            start2=time()\n",
    "            print(faces_detected[mittleres_Gesicht_X])\n",
    "            (x, y, w, h) = faces_detected[mittleres_Gesicht_X]\n",
    "            img=frame[y-p+2:y+h+p-2, x-p+2:x+w+p-2] #use only the detected face; crop it +2 to remove frame\n",
    "            #cv2.destroyAllWindows()            \n",
    "            cv2.imshow('frame', img)\n",
    "            end2=time()\n",
    "            print('detect face ',end2-start2)\n",
    "# DETECT LANDMARKS \n",
    "#             outlines=landmark_predictor(frame,faces_detected[mittleres_Gesicht_X])\n",
    "#             outlines = face_utils.shape_to_np(outlines)\n",
    "# CROP IMAGE \n",
    "            if img.shape > (width,height):\n",
    "                start3=time()\n",
    "                print('size good')\n",
    "                img_small=cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST) #resize the image to desired dimensions e.g., 256x256  \n",
    "                end3=time()\n",
    "                print('face crop', end3-start3)\n",
    "#CREATE FACE EMBEDDINGS\n",
    "                start4=time()\n",
    "                # Make images the same as they were trained on in the VGGface2 Model\n",
    "                pixels = img_small.astype('float32')\n",
    "                samples = expand_dims(pixels, axis=0)\n",
    "                # prepare the face for the model, e.g. center pixels\n",
    "                samples = preprocess_input(samples, version=2)\n",
    "                EMBEDDINGS = resnet50_features.predict(samples)\n",
    "                #print('.')\n",
    "                end4=time()\n",
    "                print('create face embeddings' , end4-start4)\n",
    "# READ CELEB EMBEDDINGS AND COMPARE  \n",
    "                start5=time()\n",
    "                EMBEDDINGS_Celebs=pd.read_json(Path.cwd() / 'EMBEDDINGS_8k.json')\n",
    "                # print(len(EMBEDDINGS.File))\n",
    "                EuDist=[]\n",
    "                for i in range(len(EMBEDDINGS_Celebs.File)):\n",
    "                    Celebs=np.array(EMBEDDINGS_Celebs.Embedding[i]) \n",
    "                    dist = np.linalg.norm(EMBEDDINGS-Celebs)\n",
    "                    EuDist.append(np.linalg.norm(EMBEDDINGS-Celebs))\n",
    "                #print(EuDist)\n",
    "                #print(np.argmin(EuDist))\n",
    "                folder_idx= EMBEDDINGS_Celebs.Name[np.argmin(EuDist)]\n",
    "                image_idx = EMBEDDINGS_Celebs.File[np.argmin(EuDist)] \n",
    "                print(' Distance value: ', np.argmin(EuDist), ' | ' , 'Name: ', EMBEDDINGS_Celebs.Name[np.argmin(EuDist)],' | ' ,' Filename: ', EMBEDDINGS_Celebs.File[np.argmin(EuDist)])\n",
    "                #plt.scatter(range(len(EMBEDDINGS.File)),EuDist)\n",
    "                end5=time()\n",
    "                print('find facematch', end5-start5)\n",
    "# PLOT IMAGES       \n",
    "                start6=time()\n",
    "            #vis = np.concatenate((img_small, img2), axis=1)\n",
    "                path=Path.cwd()\n",
    "                pfad=str(Path.cwd() / 'Celebs' / str(folder_idx) / str(image_idx))\n",
    "                Beleb=cv2.imread(pfad)\n",
    "                \n",
    "                Beleb=cv2.resize(Beleb, (np.shape(img)[0] ,np.shape(img)[1]), interpolation=cv2.INTER_NEAREST)\n",
    "                numpy_horizontal = np.hstack((img, Beleb))\n",
    "                \n",
    "                cv2.namedWindow('thats_you',cv2.WINDOW_NORMAL)\n",
    "                cv2.resizeWindow('thats_you',5*width,5*height)\n",
    "                #cv2.imshow('thats_you', Beleb)\n",
    "                cv2.imshow('thats_you', numpy_horizontal)\n",
    "                \n",
    "                #cv2.imshow('cropped',img)  \n",
    "# CLEARING ALL VARIANLES AND CONTINUE WITH THE PROGRAM\n",
    "                total=time()\n",
    "                print('totaltime ', total-start1)\n",
    "                cv2.waitKey(0) #hit any key\n",
    "                faces_detected=None\n",
    "                mittleres_Gesicht_X=None\n",
    "                img=None\n",
    "                img_small=None\n",
    "                pixels=None\n",
    "                samples=None\n",
    "                EMBEDDINGS=None\n",
    "           \n",
    "                cv2.destroyWindow('thats_you')\n",
    "                #cv2.destroyAllWindows()\n",
    "                end6=time()\n",
    "                print('print create image', end6-start6)\n",
    "            else: \n",
    "                print('image to small')\n",
    "                faces_detected=None\n",
    "                mittleres_Gesicht_X=None\n",
    "                img=None\n",
    "                img_small=None\n",
    "                pixels=None\n",
    "                samples=None\n",
    "                EMBEDDINGS=None\n",
    "                 \n",
    "\n",
    "            \n",
    "            if key == 27: #Esc key\n",
    "                break\n",
    "#             if key == 13: #Enter key\n",
    "#                 cap.release()\n",
    "#                 cv2.destroyAllWindows()\n",
    "\n",
    "                \n",
    "        else:\n",
    "            print('noface detected')\n",
    "            \n",
    "        \n",
    "\n",
    "# When everything done, release the capture\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# Now detect face and crop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T22:06:46.143146Z",
     "start_time": "2020-02-02T22:06:45.218729Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with parallel programming:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#import time\n",
    "import math \n",
    "#from imutils import face_utils\n",
    "#import dlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from numpy import expand_dims\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from time import time\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "# DEFINE VARIABLES\n",
    "#landmark_predictor = dlib.shape_predictor('/home/base/Documents/Git/Projekte/Face-celeb-rec/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(str(Path.cwd() / 'haarcascade_frontalface_alt.xml'))\n",
    "brt = 90  # value could be + or - for brightness or darkness\n",
    "cap = cv2.VideoCapture(0)\n",
    "gray=False\n",
    "p=35# frame size around detected face\n",
    "width=height=224 # size of the cropped image. Same as required for network\n",
    "mitte=np.empty(shape=[0, 0])\n",
    "mittleres_Gesicht_X=()\n",
    "\n",
    "resnet50_features = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3),\n",
    "                                pooling='avg')  # pooling: None, avg or max\n",
    "\n",
    "ret, frame = cap.read() \n",
    "framemitte=np.shape(frame)[1]/2\n",
    "\n",
    "while(True):\n",
    "# CAPTURE FRAME BY FRAME\n",
    "    \n",
    "    ret, frame = cap.read() \n",
    "    if gray==True:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    cv2.imshow('frame', frame) \n",
    "\n",
    "    \n",
    "\n",
    "#DECTECT FACE IN VIDEO CONTINUOUSLY       \n",
    "    faces_detected = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5)\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        rechteck=cv2.rectangle(frame, (x-p, y-p+2), (x+w+p, y+h+p+2), (0, 255, 0), 2)  \n",
    "        rechteck=cv2.rectangle(frame, (x-p, y-p+2), (x+int(np.ceil(height))+p, y+int(np.ceil(height))+p+2), (0, 0, 255), 2)  \n",
    "\n",
    "        cv2.imshow('frame', rechteck)     \n",
    "\n",
    "# DETECT KEY INPUT  - ESC OR FIND MOST CENTERED FACE  \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27: #Esc key\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    if key & 0xFF == ord('s'): \n",
    "        if mittleres_Gesicht_X is not ():\n",
    "            mittleres_Gesicht_X=()\n",
    "        #faces_detected = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5)\n",
    "        if faces_detected != (): # only if the cascader detected a face, otherwise error\n",
    "            start1 = time()\n",
    "            for (x,y,w,h) in faces_detected:\n",
    "                mitte=np.append(mitte,(x+w/2))\n",
    "                \n",
    "            mittleres_Gesicht_X = (np.abs(mitte - framemitte)).argmin()\n",
    "            end1 = time()\n",
    "            print('detect middel face ', end1-start1)\n",
    "# DETECT FACE\n",
    "            start2=time()\n",
    "            print(faces_detected[mittleres_Gesicht_X])\n",
    "            (x, y, w, h) = faces_detected[mittleres_Gesicht_X]\n",
    "            img=frame[y-p+2:y+h+p-2, x-p+2:x+w+p-2] #use only the detected face; crop it +2 to remove frame\n",
    "            #cv2.destroyAllWindows()            \n",
    "            cv2.imshow('frame', img)\n",
    "            end2=time()\n",
    "            print('detect face ',end2-start2)\n",
    "# DETECT LANDMARKS \n",
    "#             outlines=landmark_predictor(frame,faces_detected[mittleres_Gesicht_X])\n",
    "#             outlines = face_utils.shape_to_np(outlines)\n",
    "# CROP IMAGE \n",
    "            if img.shape > (width,height):\n",
    "                start3=time()\n",
    "                print('size good')\n",
    "                img_small=cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST) #resize the image to desired dimensions e.g., 256x256  \n",
    "                end3=time()\n",
    "                print('face crop', end3-start3)\n",
    "#CREATE FACE EMBEDDINGS\n",
    "                start4=time()\n",
    "                # Make images the same as they were trained on in the VGGface2 Model\n",
    "                pixels = img_small.astype('float32')\n",
    "                samples = expand_dims(pixels, axis=0)\n",
    "                # prepare the face for the model, e.g. center pixels\n",
    "                samples = preprocess_input(samples, version=2)\n",
    "                EMBEDDINGS = resnet50_features.predict(samples)\n",
    "                #print('.')\n",
    "                end4=time()\n",
    "                print('create face embeddings' , end4-start4)\n",
    "# READ CELEB EMBEDDINGS AND COMPARE  \n",
    "                start5=time()\n",
    "                EMBEDDINGS_Celebs=pd.read_json(Path.cwd() / 'EMBEDDINGS_8k.json')\n",
    "                # print(len(EMBEDDINGS.File))\n",
    "                np.array_split(EMBEDDINGS_Celebs, 4)\n",
    "                EuDist=[]\n",
    "                def compareToCeleb(EMBEDDINGS_Celebs, EuDist):\n",
    "                    for i in range(len(EMBEDDINGS_Celebs.File)):\n",
    "                        Celebs=np.array(EMBEDDINGS_Celebs.Embedding[i]) \n",
    "                        dist = np.linalg.norm(EMBEDDINGS-Celebs)\n",
    "                        EuDist.append(np.linalg.norm(EMBEDDINGS-Celebs))\n",
    "                        folder_idx= EMBEDDINGS_Celebs.Name[np.argmin(EuDist)]\n",
    "                        image_idx = EMBEDDINGS_Celebs.File[np.argmin(EuDist)] \n",
    "                        return folder_idx, image_idx,EuDist\n",
    "                \n",
    "                \n",
    "                print(' Distance value: ', np.argmin(EuDist), ' | ' , 'Name: ', EMBEDDINGS_Celebs.Name[np.argmin(EuDist)],' | ' ,' Filename: ', EMBEDDINGS_Celebs.File[np.argmin(EuDist)])\n",
    "                #plt.scatter(range(len(EMBEDDINGS.File)),EuDist)\n",
    "                end5=time()\n",
    "                print('find facematch', end5-start5)\n",
    "# PLOT IMAGES       \n",
    "                start6=time()\n",
    "            #vis = np.concatenate((img_small, img2), axis=1)\n",
    "                path=Path.cwd()\n",
    "                pfad=str(Path.cwd() / 'Celebs' / str(folder_idx) / str(image_idx))\n",
    "                Beleb=cv2.imread(pfad)\n",
    "                \n",
    "                Beleb=cv2.resize(Beleb, (np.shape(img)[0] ,np.shape(img)[1]), interpolation=cv2.INTER_NEAREST)\n",
    "                numpy_horizontal = np.hstack((img, Beleb))\n",
    "                \n",
    "                cv2.namedWindow('thats_you',cv2.WINDOW_NORMAL)\n",
    "                cv2.resizeWindow('thats_you',5*width,5*height)\n",
    "                #cv2.imshow('thats_you', Beleb)\n",
    "                cv2.imshow('thats_you', numpy_horizontal)\n",
    " \n",
    "                #cv2.imshow('cropped',img)  \n",
    "# CLEARING ALL VARIANLES AND CONTINUE WITH THE PROGRAM\n",
    "                total=time()\n",
    "                print('totaltime ', total-start1)\n",
    "                cv2.waitKey(0) #hit any key\n",
    "                faces_detected=None\n",
    "                mittleres_Gesicht_X=None\n",
    "                img=None\n",
    "                img_small=None\n",
    "                pixels=None\n",
    "                samples=None\n",
    "                EMBEDDINGS=None\n",
    "           \n",
    "                cv2.destroyWindow('thats_you')\n",
    "                #cv2.destroyAllWindows()\n",
    "                end6=time()\n",
    "                print('print create image', end6-start6)\n",
    "            else: \n",
    "                print('image to small')\n",
    "                faces_detected=None\n",
    "                mittleres_Gesicht_X=None\n",
    "                img=None\n",
    "                img_small=None\n",
    "                pixels=None\n",
    "                samples=None\n",
    "                EMBEDDINGS=None\n",
    "                 \n",
    "\n",
    "            \n",
    "            if key == 27: #Esc key\n",
    "                break\n",
    "#             if key == 13: #Enter key\n",
    "#                 cap.release()\n",
    "#                 cv2.destroyAllWindows()\n",
    "\n",
    "                \n",
    "        else:\n",
    "            print('noface detected')\n",
    "            \n",
    "        \n",
    "\n",
    "# When everything done, release the capture\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# Now detect face and crop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#import time\n",
    "import math \n",
    "#from imutils import face_utils\n",
    "#import dlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from numpy import expand_dims\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from time import time\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "EMBEDDINGS_Celebs=pd.read_json(Path.cwd() / 'EMBEDDINGS_8k.json')\n",
    "# print(len(EMBEDDINGS.File))\n",
    "Wasgeht=np.array_split(EMBEDDINGS_Celebs, 4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495.85px",
    "left": "1556px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
